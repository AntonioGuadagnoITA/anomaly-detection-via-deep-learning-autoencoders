{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":40951.691488,"end_time":"2022-08-11T17:06:30.811347","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-08-11T05:43:59.119859","version":"2.3.4"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Training parameters\n\nwindow = 672       # 1 week\nstride = 4         # 1 hour\nlatent_dim = 10    # Autoencoder latent dimension\nepochs = 150       # Number of epochs\nbatch_size = 8     # Batch size\nM = 200            # Montecarlo","metadata":{"_cell_guid":"940d6c9b-eeb2-4b88-84e0-0802a2bb8912","_uuid":"daee88fd-c068-4b12-aa80-f5dff1c7b11b","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.030989,"end_time":"2022-08-11T05:44:18.867360","exception":false,"start_time":"2022-08-11T05:44:18.836371","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reparametrization trick\ndef sample(args):\n    z_mean, z_log_var = args\n    eps = tf.keras.backend.random_normal(shape=(K.shape(z_mean)[0], K.int_shape(z_mean)[1]), seed=seed)\n    return z_mean + tf.exp(alpha * z_log_var) * eps","metadata":{"papermill":{"duration":0.030752,"end_time":"2022-08-11T05:44:19.415065","exception":false,"start_time":"2022-08-11T05:44:19.384313","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building the model\n\nfrom keras import backend as K\nfrom tensorflow.keras import Input\n\ninput_shape = X_train.shape[1:]\noutput_shape = X_train.shape[1:]\n\n###########\n# ENCODER #\n###########\n\nencoder_input = tf.keras.Input(shape=input_shape)\n\nx = tfkl.LSTM(64)(encoder_input)\n\nx = tfkl.LSTM(latent_dim, return_sequences=False)(x)\n\n# Latent representation: mean + log of std.dev.\nz_mu = tfkl.Dense(latent_dim, name='latent_mu')(x) # Mean\nz_sigma = tfkl.Dense(latent_dim, name='latent_sigma')(x) # Std.Dev. \n\n# Sampling a vector from the latent distribution\nz = tfkl.Lambda(sample, output_shape=(latent_dim, ), name='z')([z_mu, z_sigma])\n\nencoder = tfk.Model(encoder_input, [z_mu, z_sigma, z], name='encoder')\nprint(encoder.summary())","metadata":{"_cell_guid":"2d9f076e-ae1a-4720-b536-fca5412f83f4","_uuid":"8a40c700-5345-4ee4-95fa-07f1e57173eb","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.482988,"end_time":"2022-08-11T05:44:19.919616","exception":false,"start_time":"2022-08-11T05:44:19.436628","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###########\n# DECODER #\n###########\n\ndecoder_input = Input(shape=(latent_dim, ), name='decoder_input')\nconvlstm = tfkl.RepeatVector(window)(decoder_input)\nconvlstm = tfkl.LSTM(64, return_sequences=True)(convlstm)\ndecoder_output = tfkl.TimeDistributed(tfkl.Dense(output_shape[1]))(convlstm)\n\n# Define and summarize decoder model\ndecoder = tfk.Model(decoder_input, decoder_output, name='decoder')\ndecoder.summary()","metadata":{"_cell_guid":"6c1d6b54-49d6-48f1-a6f3-38175181fc5f","_uuid":"840b7a8f-5a52-439d-9686-79891debd8d1","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.293227,"end_time":"2022-08-11T05:44:20.234240","exception":false,"start_time":"2022-08-11T05:44:19.941013","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sampling + Reparametrization trick\ndef sample_z1(z_m, z_l_v):\n    z_mean = z_m \n    z_log_var = z_l_v\n    eps = tf.keras.backend.random_normal(shape=(K.shape(z_mean)[0], K.int_shape(z_mean)[1]), seed=seed)\n    return z_mean + tf.exp(alpha * z_log_var) * eps","metadata":{"papermill":{"duration":0.033881,"end_time":"2022-08-11T05:44:20.290249","exception":false,"start_time":"2022-08-11T05:44:20.256368","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(tfk.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = tfk.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = tfk.metrics.Mean(name=\"reconstruction_loss\")\n        self.kl_loss_tracker = tfk.metrics.Mean(name=\"kl_loss\")\n\n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n    \n    def forward(self, x):\n        outputs = {}\n        \n        z_mu, z_log_var, _ = self.encoder(x)\n        z = sample_z1(z_mu,z_log_var)\n        reconstruction = self.decoder(z)\n        \n        outputs[\"z_mu\"] = z_mu\n        outputs[\"z_log_var\"] = z_log_var\n        outputs[\"z\"] = z\n        outputs[\"reconstruction\"] = reconstruction\n        \n        return outputs\n\n    def train_step(self, y_true):\n        with tf.GradientTape() as tape:\n            \n            z_mu, z_log_var, _ = self.encoder(y_true)\n            z = sample_z1(z_mu,z_log_var)\n            y_predict = self.decoder(z)\n          \n            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tfk.losses.mse(y_true, y_predict), axis=1))\n            \n            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mu) - tf.exp(z_log_var))\n            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n            \n            total_loss = reconstruction_loss + kl_loss\n            \n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        \n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        \n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result()\n        }\n    \n    def test_step(self, data): #https://github.com/keras-team/keras-io/issues/38\n\n        z_mu, z_log_var, _ = self.encoder(data)\n        z = sample_z1(z_mu,z_log_var)\n        y_predict = self.decoder(z)\n          \n        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tfk.losses.mse(data, y_predict), axis=1))\n            \n        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mu) - tf.exp(z_log_var))\n        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n            \n        total_loss = reconstruction_loss + kl_loss\n        \n        return {\n            \"loss\": total_loss,\n            \"reconstruction_loss\": reconstruction_loss,\n            \"kl_loss\": kl_loss\n        }","metadata":{"_cell_guid":"6abeeb1d-b047-4fe9-a3e5-ed5bb59bf70d","_uuid":"36931ab9-f55f-428f-8cad-6d52e9521aec","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.043168,"end_time":"2022-08-11T05:44:20.354888","exception":false,"start_time":"2022-08-11T05:44:20.311720","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae = VAE(encoder, decoder)\n\nseed = 42\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\n\nvae.compile(optimizer=tfk.optimizers.Adam())\nvae.fit(x = X_train,\n        validation_data = (X_val, None),\n        epochs=epochs, \n        batch_size=batch_size)\nvae.fit(x = X_train,\n        validation_data = (X_val, None),\n        epochs=epochs, \n        batch_size=batch_size,\n        callbacks=[tfk.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True), tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-5)]\n       )","metadata":{"_cell_guid":"3a2dfb11-ea50-4bf2-9c89-4ac6e312f9e4","_uuid":"893a7da0-7591-4c34-b59e-96e748d40a55","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":39206.398218,"end_time":"2022-08-11T16:37:46.774674","exception":false,"start_time":"2022-08-11T05:44:20.376456","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}